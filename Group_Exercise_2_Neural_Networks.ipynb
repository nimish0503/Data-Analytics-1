{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4780b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, SimpleRNN, LSTM, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"healthcare_dataset.csv\")\n",
    "\n",
    "# Data preprocessing\n",
    "# Encode categorical columns\n",
    "label_encoders = {}\n",
    "for column in [\"Gender\", \"Smoking_Status\"]:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Separate features and target\n",
    "target = \"Readmission_Risk\"\n",
    "X = data.drop(columns=[target])\n",
    "y = data[target]\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert target to categorical\n",
    "num_classes = len(y.unique())\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# Define models\n",
    "\n",
    "def build_ffnn(input_dim, output_dim):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_dim=input_dim),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(output_dim, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_cnn(input_shape, output_dim):\n",
    "    model = Sequential([\n",
    "        Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(output_dim, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_rnn(input_shape, output_dim):\n",
    "    model = Sequential([\n",
    "        SimpleRNN(32, activation='relu', input_shape=input_shape),\n",
    "        Dense(output_dim, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_lstm(input_shape, output_dim):\n",
    "    model = Sequential([\n",
    "        LSTM(32, activation='relu', input_shape=input_shape),\n",
    "        Dense(output_dim, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Train and evaluate models\n",
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test, epochs=10, batch_size=32):\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0)\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return history, test_loss, test_accuracy\n",
    "\n",
    "# Reshape for CNN, RNN, and LSTM\n",
    "input_shape_cnn = (X_train.shape[1], 1)\n",
    "X_train_cnn = X_train.reshape(-1, X_train.shape[1], 1)\n",
    "X_test_cnn = X_test.reshape(-1, X_test.shape[1], 1)\n",
    "\n",
    "input_shape_rnn = (X_train.shape[1], 1)\n",
    "X_train_rnn = X_train_cnn  # Same reshaping as CNN\n",
    "X_test_rnn = X_test_cnn\n",
    "\n",
    "input_shape_lstm = (X_train.shape[1], 1)\n",
    "X_train_lstm = X_train_cnn  # Same reshaping as CNN\n",
    "X_test_lstm = X_test_cnn\n",
    "\n",
    "# FFNN\n",
    "ffnn_model = build_ffnn(X_train.shape[1], num_classes)\n",
    "ffnn_history, ffnn_loss, ffnn_accuracy = train_and_evaluate(ffnn_model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# CNN\n",
    "cnn_model = build_cnn(input_shape_cnn, num_classes)\n",
    "cnn_history, cnn_loss, cnn_accuracy = train_and_evaluate(cnn_model, X_train_cnn, y_train, X_test_cnn, y_test)\n",
    "\n",
    "# RNN\n",
    "rnn_model = build_rnn(input_shape_rnn, num_classes)\n",
    "rnn_history, rnn_loss, rnn_accuracy = train_and_evaluate(rnn_model, X_train_rnn, y_train, X_test_rnn, y_test)\n",
    "\n",
    "# LSTM\n",
    "lstm_model = build_lstm(input_shape_lstm, num_classes)\n",
    "lstm_history, lstm_loss, lstm_accuracy = train_and_evaluate(lstm_model, X_train_lstm, y_train, X_test_lstm, y_test)\n",
    "\n",
    "# Plot performance metrics\n",
    "def plot_history(histories, labels):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for history, label in zip(histories, labels):\n",
    "        plt.plot(history.history['accuracy'], label=f'{label} Train')\n",
    "        plt.plot(history.history['val_accuracy'], label=f'{label} Val')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_history([ffnn_history, cnn_history, rnn_history, lstm_history], ['FFNN', 'CNN', 'RNN', 'LSTM'])\n",
    "\n",
    "# Compare results\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['FFNN', 'CNN', 'RNN', 'LSTM'],\n",
    "    'Test Accuracy': [ffnn_accuracy, cnn_accuracy, rnn_accuracy, lstm_accuracy],\n",
    "    'Test Loss': [ffnn_loss, cnn_loss, rnn_loss, lstm_loss]\n",
    "})\n",
    "\n",
    "print(results)\n",
    "\n",
    "# Identify best-performing model\n",
    "best_model = results.loc[results['Test Accuracy'].idxmax()]\n",
    "print(\"Best Performing Model:\", best_model)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}